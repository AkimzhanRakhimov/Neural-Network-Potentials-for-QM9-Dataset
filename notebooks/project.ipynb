{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF2sEi/cPRo8nKcseigaff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkimzhanRakhimov/Neural-Network-Potentials-for-QM9-Dataset/blob/main/notebooks/NNP_and_Verlet_Integrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ase torch-geometric rdkit"
      ],
      "metadata": {
        "id": "KjHTJgrhBy95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "import torch\n",
        "import ase\n",
        "from ase import Atoms\n",
        "from google.colab import drive\n",
        "import os\n",
        "from ase.io import write\n",
        "import numpy as np\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "print(\"Imports ok\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGd1cXPA2BBw",
        "outputId": "9ef20ac8-9c7d-4f14-c518-e11751ff2bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "if os.path.exists(\"/content/drive/MyDrive/NNP\"):\n",
        "  print(\"Path exist already\")\n",
        "else:\n",
        "  os.mkdir(\"/content/drive/MyDrive/NNP\")\n",
        "  print(\"Path has been created successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6xgOaBLjzom",
        "outputId": "823d99d7-61ad-4140-9ee6-13378abfe945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Path exist already\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=QM9(root=\"qm9_data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRcZWCSnsI3a",
        "outputId": "be30aaa0-8947-4be6-d335-92830b4f4757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/molnet_publish/qm9.zip\n",
            "Extracting qm9_data/raw/qm9.zip\n",
            "Downloading https://ndownloader.figshare.com/files/3195404\n",
            "Processing...\n",
            "100%|██████████| 133885/133885 [03:06<00:00, 718.05it/s]\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bounded_Dataset(Dataset):\n",
        "  def __init__(self,dataset_name,n_samples=10000):\n",
        "    self.data=dataset_name[:n_samples]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    d=self.data[idx]\n",
        "    return{\n",
        "        \"z\":d.z.float(),\n",
        "        \"pos\":d.pos.float(),\n",
        "        \"energy\":d.y[0,10].float()\n",
        "    }\n",
        "training_dataset=Bounded_Dataset(dataset)"
      ],
      "metadata": {
        "id": "AVExA2clIaBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "class AtomMLP(nn.Module):\n",
        "  def __init__(self,n_atom_types=100,hidden_dim=64,output_features=1):\n",
        "    super().__init__()\n",
        "    self.embeddings=nn.Embedding(n_atom_types,embedding_dim=64)\n",
        "    # Pytorch architecture allows us to use bathes(atoms in molecula) in neural network loop\n",
        "    self.mlp=nn.Sequential(\n",
        "        nn.Linear(hidden_dim+15,hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim,1)\n",
        "    )\n",
        "  def forward(self,z,pos):\n",
        "\n",
        "\n",
        "    dists=torch.cdist(pos,pos)\n",
        "    N=pos.shape[1]\n",
        "\n",
        "    mask=1-torch.eye(N,device=pos.device)\n",
        "    dists=dists*mask\n",
        "    dists_sorted,_=torch.sort(dists,dim=2)\n",
        "    if N<=15:\n",
        "      zeros=torch.zeros((1,N,16-N),device=pos.device)\n",
        "      dists_sorted=torch.cat([dists_sorted,zeros],dim=2)\n",
        "\n",
        "    dists_sorted=dists_sorted[:,:,1:16]\n",
        "\n",
        "    h=self.embeddings(z.long())\n",
        "    atom_input=torch.cat([h,dists_sorted],dim=2)\n",
        "    energy=self.mlp(atom_input).sum()\n",
        "    return energy\n",
        "\n",
        "# Here i create GNN architecture\n",
        "\n",
        "class AtomEmbeddings(nn.Module):\n",
        "  def __init__(self,num_types,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(num_types,hidden_dim)\n",
        "\n",
        "  def forward(self,z):\n",
        "    h=self.embedding(z.long())\n",
        "    return h\n",
        "\n",
        "class MessagePassingLayerV0(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.mlp=nn.Sequential(\n",
        "        nn.Linear(2*hidden_dim+1,hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim,hidden_dim)\n",
        "    )\n",
        "  def forward(self,h,edge_index,edge_attr):\n",
        "    m=torch.zeros_like(h).to(device)\n",
        "    for idx in range(edge_index.shape[1]):\n",
        "      i,j=edge_index[:,idx]\n",
        "      msg_input=torch.cat([h[i],h[j],edge_attr[idx]],dim=0)\n",
        "      m[i]+=self.mlp(msg_input)\n",
        "    h=h+m\n",
        "    return h\n",
        "class MessagePassingLayerV1(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.mlp=nn.Sequential(\n",
        "        nn.Linear(hidden_dim+1,hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim,hidden_dim)\n",
        "    )\n",
        "  def forward(self,h,edge_index,edge_attr):\n",
        "    m=torch.zeros_like(h)\n",
        "    for idx in range(edge_index.shape[1]):\n",
        "      i,j=edge_index[:,idx]\n",
        "      msg_input=torch.cat([h[j],edge_attr[idx]])\n",
        "      m[i]+=self.mlp(msg_input)\n",
        "    h=h+m\n",
        "    return h\n",
        "class EnergyHead(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.mlp=nn.Sequential(\n",
        "        nn.Linear(hidden_dim,hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim,1)\n",
        "    )\n",
        "  def forward(self,h):\n",
        "    return self.mlp(h).sum()\n",
        "class AtomGNN(nn.Module):\n",
        "  def __init__(self,num_types,hidden_dim,layers_num=3):\n",
        "    super().__init__()\n",
        "    self.embedding=AtomEmbeddings(num_types,hidden_dim)\n",
        "    self.embedding.to(device)\n",
        "    self.layers=nn.ModuleList([MessagePassingLayerV0(hidden_dim) for _ in range(layers_num)])\n",
        "    for layer in self.layers:\n",
        "      layer.to(device)\n",
        "    self.energy=EnergyHead(hidden_dim)\n",
        "    self.energy.to(device)\n",
        "  def forward(self,z,pos,cutoff=5.0):\n",
        "    N=pos.shape[1]\n",
        "    dists=torch.cdist(pos,pos).squeeze(0)\n",
        "    h=self.embedding(z).squeeze(0)\n",
        "    mask=(dists<cutoff) & (~torch.eye(N, dtype=bool,device=device ))\n",
        "    edge_index=mask.nonzero(as_tuple=False).T\n",
        "    edge_attr=dists[mask].unsqueeze(1)\n",
        "    for layer in self.layers:\n",
        "      h=layer(h,edge_index,edge_attr)\n",
        "    return self.energy(h)\n"
      ],
      "metadata": {
        "id": "lvYxSNPmRi1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model\n",
        "model=AtomMLP()\n",
        "# model=AtomGNN(10,64,3)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ZZb4cPRvqGXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae6d418-4f35-4225-ed5c-4628ce8191d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AtomMLP(\n",
              "  (embeddings): Embedding(100, 64)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=79, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader=DataLoader(dataset=training_dataset,batch_size=1,shuffle=True)\n",
        "\n",
        "optimizer=torch.optim.Adam(params=model.parameters(),lr=1e-2)\n",
        "loss_fn=nn.MSELoss()"
      ],
      "metadata": {
        "id": "JnoqvUctgGE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  model.train()\n",
        "  total_loss=0\n",
        "  for batch in tqdm(train_dataloader):\n",
        "    z=batch['z'].to(device)\n",
        "    pos=batch['pos'].to(device)\n",
        "    energy=batch['energy'].to(device)\n",
        "    # forward pass\n",
        "\n",
        "    energy_pred=model(z,pos)\n",
        "    # count the loss\n",
        "    loss=loss_fn(energy_pred,energy)\n",
        "    # zero grad\n",
        "    optimizer.zero_grad()\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "    # update the weights\n",
        "    optimizer.step()\n",
        "    total_loss+=loss\n",
        "  print(f\"Loss:{total_loss/len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "id": "R7lxCJtDsIm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(obj=model.state_dict(),f=\"/content/drive/MyDrive/NNP/model_1.pth\")\n",
        "print(\"Model has been saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEiMIn7DJj9e",
        "outputId": "5ac43849-2e92-439c-f2f5-48623602b32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has been saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/NNP/model_1.pth\"))\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NNP/model_1.pth\"))\n",
        "print(\"Model has been loaded\")\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "8_tpRzrJSCMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490f76f3-a1f6-4689-e2f2-ae94da9e9bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has been loaded\n",
            "OrderedDict({'embeddings.weight': tensor([[-0.1438,  0.5092, -0.9404,  ...,  1.7845,  0.6640, -1.3630],\n",
            "        [-2.4863,  5.8489,  2.3534,  ..., -5.7325,  0.1760, -2.6862],\n",
            "        [-0.0813,  2.6949,  0.5698,  ..., -2.8501, -0.6369,  1.9235],\n",
            "        ...,\n",
            "        [-1.2195,  0.0170, -0.5504,  ..., -1.2942,  0.8812,  1.6265],\n",
            "        [-1.4461,  0.5560,  0.7835,  ...,  0.7141,  0.5716, -0.6407],\n",
            "        [-1.7449, -1.0938,  0.6311,  ...,  1.7004, -0.9643, -1.0664]]), 'mlp.0.weight': tensor([[-0.6601, -0.5862, -0.3912,  ..., -0.6122, -0.3542, -0.4546],\n",
            "        [-1.3509, -0.2140, -3.6609,  ..., -2.6910, -3.1587, -3.2637],\n",
            "        [-5.0041, -5.7155, -0.9885,  ..., -2.2931, -2.3549, -2.2482],\n",
            "        ...,\n",
            "        [-2.7026, -4.2215, -2.9582,  ..., -5.2760, -4.9126, -4.3879],\n",
            "        [-4.3435, -0.3502, -9.8305,  ..., -5.2977, -8.7898, -8.7519],\n",
            "        [-4.3830, -5.7389, -5.7398,  ..., -6.1473, -6.0429, -5.6927]]), 'mlp.0.bias': tensor([ -0.6764,  -4.7322,  -2.1416,  -0.2560,   0.0560,  -1.4919,  -9.3327,\n",
            "         -5.8229,   0.6131,  -0.9109,  -4.5959,   0.4200,  -1.3098,   0.4473,\n",
            "        -12.2813,  -9.1186,   2.4225,  -5.8037,   0.0854,  -1.7018,  22.7622,\n",
            "         -1.9199, -13.6279,  -2.3155, -11.3876,  -0.3296,  -4.7578,  -5.1398,\n",
            "          1.0969,  -5.0669,  -4.2220,   0.1816,  -0.8654,  -3.2485,   1.1276,\n",
            "         -0.7301, -14.9596,  -4.6771,  -6.0930,  -8.7048,  -3.3205,  -9.6964,\n",
            "         -3.5207,  -0.0683,  -0.8763,  -4.8127,  -4.5857, -10.7800,   0.7517,\n",
            "         -3.2144, -12.4184,  -4.8061,  -7.2067, -12.6361,   0.8654,   0.5934,\n",
            "         -3.8646,   0.0541,  -4.3954,  -1.6545,  -1.9116,  -8.4254, -11.6928,\n",
            "         -0.1862]), 'mlp.2.weight': tensor([[-0.1255, -2.5714,  1.0639,  4.5391, -0.0068,  3.2001, -2.6089, -1.7943,\n",
            "          3.4531, -2.4549, -1.0918,  1.2900,  0.8806,  1.9983, -0.7886, -0.3861,\n",
            "         -0.5310,  1.8611, -0.1285, -0.1409, -2.9836,  2.3284, -1.8506, -0.1592,\n",
            "          0.4667,  2.0898, -2.5432, -2.7350, -0.1759,  0.0096,  0.8462,  0.0335,\n",
            "         -2.4734, -3.1685, -0.2162, -0.7475,  0.6115,  1.7884, -0.5859,  0.9585,\n",
            "          3.0025, -1.8593,  3.0575, -1.4735, -0.1201, -2.4602,  2.6364, -0.1204,\n",
            "          1.3336,  1.6183, -2.3297, -0.2654,  1.1868, -1.9481,  0.6875,  1.9580,\n",
            "          1.2508,  2.4213,  1.5035,  0.3586,  0.0175,  1.5905,  1.3265,  1.7127]]), 'mlp.2.bias': tensor([-16.9466])})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masses(all_masses):\n",
        "  masses=[atomic_masses[mass] for mass in all_masses]\n",
        "  return torch.tensor(masses).unsqueeze(dim=1)\n",
        "atomic_masses={1:1.0,6:12.0,7:14.0,8:16.0,9:19.0}\n",
        "batch=next(iter(train_dataloader))\n",
        "z=batch[\"z\"]\n",
        "pos=batch[\"pos\"]\n",
        "pos.requires_grad=True\n",
        "z_list=list(map(int,z.squeeze(dim=0).tolist()))\n",
        "masses=get_masses(z_list)\n",
        "atoms=Atoms(numbers=z_list,positions=pos.squeeze().detach().numpy())\n",
        "traj=[]\n",
        "print(atoms.positions)\n",
        "def integrator(model,masses,z,pos,u,dt=0.002):\n",
        "  pos.requires_grad_=True\n",
        "  energy_pred=model(z,pos)\n",
        "\n",
        "  forces=-torch.autograd.grad(energy_pred,pos,create_graph=True)[0].squeeze(dim=0)\n",
        "  acc=forces/masses\n",
        "  u_new=u+0.5*acc*dt\n",
        "\n",
        "  pos_new=pos+u_new*dt\n",
        "  return pos_new,u_new\n",
        "pos_new=pos\n",
        "u_new=0\n",
        "\n"
      ],
      "metadata": {
        "id": "wOEW9ePCTTjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2151d6-f0ee-43c6-c2bb-2fd14a9480d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.0105      1.45840001  0.0083    ]\n",
            " [ 0.0064      0.         -0.0288    ]\n",
            " [-0.1003     -0.69669998 -1.19509995]\n",
            " [-0.081      -2.05679989 -1.19350004]\n",
            " [ 0.0448     -2.7723999  -0.0355    ]\n",
            " [ 0.147      -2.11409998  1.07969999]\n",
            " [ 0.1393     -0.65820003  1.20879996]\n",
            " [ 0.2343     -0.0259      2.2486999 ]\n",
            " [ 0.91500002  1.82840002  0.45570001]\n",
            " [-0.1174      1.84200001 -1.00660002]\n",
            " [-0.83929998  1.80359995  0.63099998]\n",
            " [-0.1991     -0.1106     -2.1013    ]\n",
            " [-0.1654     -2.61459994 -2.11739993]\n",
            " [ 0.24779999 -2.66659999  2.01090002]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(500):\n",
        "  traj.append(atoms.copy())\n",
        "  pos_new,u_new=integrator(model,masses,z,pos_new,u_new,dt=0.02)\n",
        "  atoms=Atoms(numbers=z_list,positions=pos_new.squeeze().cpu().clone().detach().numpy())\n",
        "\n",
        "write(\"/content/drive/MyDrive/NNP/Methan_dynamic.xyz\",traj)"
      ],
      "metadata": {
        "id": "rr251rdJzy77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
